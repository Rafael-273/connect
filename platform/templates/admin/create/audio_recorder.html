{% extends 'base.html' %}
{% load static %}

{% block title %}Tradução Simultânea{% endblock %}

{% block content %}
<section class="m-0 h-screen text-black bg-white box-border grid grid-rows-[1fr_2fr_1fr] justify-items-center py-6 md:py-0 w-full">
  <div></div>

  <div class="flex flex-col gap-6 justify-center items-center px-6 md:px-0 w-full md:w-1/2">
    <div class="text-center flex flex-col gap-2">
      <h1 class="text-4xl md:text-6xl font-bold text-[var(--color-primary)]">Tradução Simultânea</h1>
      <p class="text-sm md:text-base text-gray-700 mt-2">
        Ao iniciar, o microfone será ativado e o áudio enviado para tradução.
      </p>
    </div>

    <div class="flex flex-col items-center gap-4 w-full">
      <div class="flex gap-4 justify-center">
        <button id="startBtn" class="flex items-center justify-center gap-2 bg-[var(--color-dark)] hover:bg-[var(--color-danger)] text-white font-semibold py-2 px-6 rounded-xl transition disabled:opacity-50">
          🎙️ <span>Iniciar Áudio</span>
        </button>

        <button id="stopBtn" disabled class="flex items-center justify-center gap-2 bg-[var(--color-primary)] hover:bg-[var(--color-danger)] text-white font-semibold py-2 px-6 rounded-xl transition disabled:opacity-50">
          ⏹️ <span>Parar</span>
        </button>
      </div>
    </div>

    <div id="transcription" class="text-center text-lg text-gray-900 font-medium"></div>
  </div>

  <div></div>
</section>

<script>
  const startBtn = document.getElementById('startBtn');
  const stopBtn = document.getElementById('stopBtn');
  const transcriptionEl = document.getElementById('transcription');

  let audioContext;
  let workletNode;
  let micStream;
  let socket;

  startBtn.addEventListener('click', async () => {
    console.log("Botão iniciar clicado");

    try {
      const protocol = window.location.protocol === 'https:' ? 'wss://' : 'ws://';
      socket = new WebSocket(protocol + window.location.host + '/ws/audio/');

      socket.onopen = () => {
        console.log("✅ WebSocket aberto");
      };

      socket.onmessage = (event) => {
        const data = JSON.parse(event.data);
        if (data.message_type === "partial") {
          transcriptionEl.innerText = "⏳ " + data.message;
        } else if (data.message_type === "final") {
          transcriptionEl.innerText = "✅ " + data.message;
        } else {
          transcriptionEl.innerText = data.message || "⚠️ Sem mensagem.";
        }
      };

      socket.onerror = (e) => {
        console.error("❌ Erro WebSocket:", e);
      };

      socket.onclose = () => {
        console.warn("⚠️ WebSocket fechado");
      };

      audioContext = new AudioContext({ sampleRate: 16000 });

      await audioContext.audioWorklet.addModule('/static/translator/recorder-worklet.js');

      micStream = await navigator.mediaDevices.getUserMedia({ audio: true });

      const micSource = audioContext.createMediaStreamSource(micStream);
      workletNode = new AudioWorkletNode(audioContext, 'recorder-processor');

      micSource.connect(workletNode);
      workletNode.connect(audioContext.destination);

      workletNode.port.onmessage = (event) => {
        const float32 = event.data;
        const wavBytes = convertFloat32ToWavBytes(float32, audioContext.sampleRate);
        const b64 = btoa(String.fromCharCode(...wavBytes));

        if (socket.readyState === WebSocket.OPEN) {
          socket.send(JSON.stringify({ audio: `data:audio/wav;base64,${b64}` }));
        }
      };

      startBtn.disabled = true;
      stopBtn.disabled = false;

      console.log("🎙️ Captura de áudio iniciada");

    } catch (err) {
      console.error("🚫 Erro:", err);
    }
  });

  stopBtn.addEventListener('click', () => {
    console.log("⏹ Botão parar clicado");

    if (workletNode) workletNode.disconnect();
    if (audioContext) audioContext.close();
    if (micStream) {
      micStream.getTracks().forEach(track => track.stop());
    }
    if (socket && socket.readyState === WebSocket.OPEN) {
      socket.close();
    }

    startBtn.disabled = false;
    stopBtn.disabled = true;

    console.log("🛑 Captura encerrada");
  });

  function convertFloat32ToWavBytes(float32Buffer, sampleRate = 16000) {
    const int16Buffer = new Int16Array(float32Buffer.length);
    for (let i = 0; i < float32Buffer.length; i++) {
      const s = Math.max(-1, Math.min(1, float32Buffer[i]));
      int16Buffer[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
    }

    const buffer = new ArrayBuffer(44 + int16Buffer.length * 2);
    const view = new DataView(buffer);

    function writeString(view, offset, str) {
      for (let i = 0; i < str.length; i++) {
        view.setUint8(offset + i, str.charCodeAt(i));
      }
    }

    writeString(view, 0, 'RIFF');
    view.setUint32(4, 36 + int16Buffer.length * 2, true);
    writeString(view, 8, 'WAVE');
    writeString(view, 12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, 1, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * 2, true);
    view.setUint16(32, 2, true);
    view.setUint16(34, 16, true);
    writeString(view, 36, 'data');
    view.setUint32(40, int16Buffer.length * 2, true);

    let offset = 44;
    for (let i = 0; i < int16Buffer.length; i++) {
      view.setInt16(offset, int16Buffer[i], true);
      offset += 2;
    }

    return new Uint8Array(buffer);
  }
</script>
{% endblock %}
